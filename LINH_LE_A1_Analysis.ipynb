{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***\n",
    "\n",
    "\n",
    "<br><strong>Assignment 1 | Regression-Based Analysis</strong><br>\n",
    "<strong>Data Analysis and Code</strong><br>\n",
    "Machine Learning | Cohort 3<br>\n",
    "Linh Le<br>\n",
    "<br>\n",
    "\n",
    "***\n",
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "The purpose of this model is to predict the expected revenue from each Apprentice Chef customer within their first year of orders. <br><br>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dataset Exploration</h3><br>\n",
    "<strong>Understanding the Data</strong>\n",
    "\n",
    "First, as with every new dataset, we have to get an initial feel for the data. This includes becoming familiarized with all the attributes (or columns) of the data and their types, checking for missing values, and looking at initial correlation with the response variable, Revenue.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import pandas as pd                                     # data science essentials\n",
    "import seaborn as sns                                   # essential graphical output\n",
    "import matplotlib.pyplot as plt                         # enhanced graphical output\n",
    "import statsmodels.formula.api as smf                   # regression modeling\n",
    "from sklearn.model_selection import train_test_split    # train/test split\n",
    "import sklearn.linear_model                             # linear models (scikit-learn)\n",
    "\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "# specifying file name\n",
    "file = \"Apprentice_Chef_Dataset.xlsx\"\n",
    "\n",
    "\n",
    "# reading the file into Python\n",
    "chef = pd.read_excel(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for null values in the dataset\n",
    "\n",
    "chef.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking type of each variable\n",
    "\n",
    "chef.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at a heatmap of the variables to see which ones are most correlated with Revenue\n",
    "\n",
    "df_corr = chef.corr().round(2)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "\n",
    "sns.heatmap(df_corr,\n",
    "            cmap = 'coolwarm',\n",
    "            square = True,\n",
    "            annot = True,\n",
    "            linecolor = 'black',\n",
    "            linewidths = 0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a (Pearson) correlation matrix\n",
    "df_corr = chef.corr().round(2)\n",
    "\n",
    "\n",
    "# printing (Pearson) correlations with SalePrice\n",
    "print(df_corr.loc['REVENUE'].sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the generated correlation heatmap and Pearson correlation matrix, we can see that the variables most correlated with Revenue are: Average Prep Vid Time (which is the average time in seconds a customer watched instructional videos for meal preparation), Median Meal Rating, Total Meals Ordered, Average Clicks per Visit (negatively correlated), Total Photos Viewed, Master Classes Attended, and Largest Order Size.\n",
    "\n",
    "We can start by first taking a look at the relationship between each of these variables and the response variable (revenue). Here, we are developing a base model by building a simple linear regression (OLS) to predict the revenue of Apprentice Chef. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a base model with initial most-correlated features\n",
    "\n",
    "# blueprinting a model type\n",
    "lm_initial = smf.ols(formula = \"\"\"REVENUE ~ chef['AVG_PREP_VID_TIME'] +\n",
    "                                            chef['MEDIAN_MEAL_RATING'] +\n",
    "                                            chef['TOTAL_MEALS_ORDERED'] +\n",
    "                                            chef['AVG_CLICKS_PER_VISIT'] +\n",
    "                                            chef['TOTAL_PHOTOS_VIEWED'] +\n",
    "                                            chef['MASTER_CLASSES_ATTENDED'] +\n",
    "                                            chef['LARGEST_ORDER_SIZE']\"\"\",\n",
    "                     data = chef)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# telling Python to run the data through the blueprint\n",
    "results_initial = lm_initial.fit()\n",
    "\n",
    "\n",
    "# printing the results\n",
    "print(results_initial.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Output:</strong><br>\n",
    "The base model generated an R-squared value of 0.610.<br>\n",
    "Now, we need to perform feature engineering to build a new model with better predictive capabilities than this base model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Types</h3><br>\n",
    "\n",
    "<strong>Sorting variables according to data type (CONTINUOUS/INTERVAL, BINARY, COUNT, CATEGORICAL, or DISCRETE).</strong><br>\n",
    "\n",
    "To get an even better understanding of the data, I am going to sort the variables according to assumptions of its type. This allows for better organization and helps to better visualize the story that the data is telling, and can make way for different features we are going to be engineering.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at quantiles to help categorize data types\n",
    "\n",
    "chef.loc[:, :].quantile([0.96,\n",
    "                         0.97,\n",
    "                         0.98,\n",
    "                         0.99,\n",
    "                        1.00])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Things to note from quantile analysis:</strong>\n",
    "\n",
    "When looking at every 20th quantile (from 0.2 to 1.0), values spike from the 80th percentile to the 100th percentile. Upon digging deeper into the top 5th percentile, it can be seen that the drastic increase occurs from the 99th to the 100th percentile. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making assumptions of data type based on quantile analysis and basid dataset information\n",
    "\n",
    "\"\"\"\n",
    "# CONTINUOUS OR INTERVAL \n",
    "REVENUE\n",
    "AVG_TIME_PER_SITE_VISIT\n",
    "FOLLOWED_RECOMMENDATIONS_PCT\n",
    "AVG_PREP_VID_TIME\n",
    "\n",
    "\n",
    "\n",
    "# BINARY\n",
    "CROSS_SELL_SUCCESS\n",
    "MOBILE_NUMBER\n",
    "TASTES_AND_PREFERENCES\n",
    "PACKAGE_LOCKER\n",
    "REFRIGERATED_LOCKER\n",
    "\n",
    "\n",
    "\n",
    "# COUNT\n",
    "TOTAL_MEALS_ORDERED\n",
    "UNIQUE_MEALS_PURCH\n",
    "CONTACTS_W_CUSTOMER_SERVICE\n",
    "PRODUCT_CATEGORIES_VIEWED\n",
    "CANCELLATIONS_BEFORE_NOON\n",
    "CANCELLATIONS_AFTER_NOON\n",
    "PC_LOGINS\n",
    "MOBILE_LOGINS\n",
    "EARLY_DELIVERIES\n",
    "LATE_DELIVERIES\n",
    "LARGEST_ORDER_SIZE\n",
    "MASTER_CLASSES_ATTENDED\n",
    "AVG_CLICKS_PER_VISIT\n",
    "TOTAL_PHOTOS_VIEWED\n",
    "MEDIAN_MEAL_RATING\n",
    "WEEKLY_PLAN\n",
    "\n",
    "\n",
    "\n",
    "# CATEGORICAL\n",
    "EMAIL -- Could categorize emails into personal, professional, and junk \n",
    "\n",
    "\n",
    "\n",
    "# DISCRETE\n",
    "NAME\n",
    "EMAIL\n",
    "FIRST_NAME\n",
    "FAMILY_NAME\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Flagging Missing Values</h3><br>\n",
    "\n",
    "When checking for missing values above, one value was discovered to be missing, in the column \"FAMILY_NAME\". As this cannot be accurately imputed, I decided to impute this value with \"Unknown\". <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping over columns with missing values\n",
    "for col in chef:\n",
    "\n",
    "    # creating columns with 1s if missing and 0 if not\n",
    "    if chef[col].isnull().astype(int).sum() > 0:\n",
    "        chef['m_'+col] = chef[col].isnull().astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an imputation value (through soft-coding)\n",
    "fill = \"Unknown\"\n",
    "\n",
    "# Imputing 'FAMILY_NAME'\n",
    "chef['FAMILY_NAME'] = chef['FAMILY_NAME'].fillna(fill)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure all missing values have been taken care of\n",
    "chef.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Outlier Analysis</h3><br>\n",
    "\n",
    "To maximize model accuracy, outliers need to be identified and defined to classify whether or not a data point deviates from the overall pattern. <br>\n",
    "This outlier analysis will comprise three steps: <br>\n",
    "1. Firstly a histogram will be created for every variable in the dataset.\n",
    "2. Outlier thresholds (both lower and upper) will be identified and flagged based on these histograms.\n",
    "3. From these thresholds, features (columns) for outliers will be created to be included in the predictive model (if significant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a comprehensive list of variables\n",
    "\n",
    "all_variables =['REVENUE',\n",
    "                'CROSS_SELL_SUCCESS', \n",
    "                'TOTAL_MEALS_ORDERED', \n",
    "                'UNIQUE_MEALS_PURCH',\n",
    "                'CONTACTS_W_CUSTOMER_SERVICE', \n",
    "                'PRODUCT_CATEGORIES_VIEWED',\n",
    "                'AVG_TIME_PER_SITE_VISIT', \n",
    "                'MOBILE_NUMBER', \n",
    "                'CANCELLATIONS_BEFORE_NOON',\n",
    "                'CANCELLATIONS_AFTER_NOON', \n",
    "                'TASTES_AND_PREFERENCES', \n",
    "                'MOBILE_LOGINS',\n",
    "                'PC_LOGINS', \n",
    "                'WEEKLY_PLAN', \n",
    "                'EARLY_DELIVERIES', \n",
    "                'LATE_DELIVERIES',\n",
    "                'PACKAGE_LOCKER', \n",
    "                'REFRIGERATED_LOCKER', \n",
    "                'FOLLOWED_RECOMMENDATIONS_PCT',\n",
    "                'AVG_PREP_VID_TIME', \n",
    "                'LARGEST_ORDER_SIZE', \n",
    "                'MASTER_CLASSES_ATTENDED',\n",
    "                'MEDIAN_MEAL_RATING', \n",
    "                'AVG_CLICKS_PER_VISIT', \n",
    "                'TOTAL_PHOTOS_VIEWED']\n",
    "\n",
    "\n",
    "# Creating a list of explanatory variables (x variables)\n",
    "\n",
    "x_variables =['CROSS_SELL_SUCCESS', \n",
    "              'TOTAL_MEALS_ORDERED', \n",
    "              'UNIQUE_MEALS_PURCH',\n",
    "              'CONTACTS_W_CUSTOMER_SERVICE', \n",
    "              'PRODUCT_CATEGORIES_VIEWED',\n",
    "              'AVG_TIME_PER_SITE_VISIT', \n",
    "              'MOBILE_NUMBER', \n",
    "              'CANCELLATIONS_BEFORE_NOON',\n",
    "              'CANCELLATIONS_AFTER_NOON', \n",
    "              'TASTES_AND_PREFERENCES', \n",
    "              'MOBILE_LOGINS',\n",
    "              'PC_LOGINS', \n",
    "              'WEEKLY_PLAN', \n",
    "              'EARLY_DELIVERIES', \n",
    "              'LATE_DELIVERIES',\n",
    "              'PACKAGE_LOCKER', \n",
    "              'REFRIGERATED_LOCKER', \n",
    "              'FOLLOWED_RECOMMENDATIONS_PCT',\n",
    "              'AVG_PREP_VID_TIME', \n",
    "              'LARGEST_ORDER_SIZE', \n",
    "              'MASTER_CLASSES_ATTENDED',\n",
    "              'MEDIAN_MEAL_RATING', \n",
    "              'AVG_CLICKS_PER_VISIT', \n",
    "              'TOTAL_PHOTOS_VIEWED']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Visual EDA (Histograms)\n",
    "########################\n",
    "\n",
    "# Loop to create a histogram for every variable in the chef dataset\n",
    "for i in all_variables:\n",
    "    fig, ax = plt.subplots(figsize = (10, 8))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.distplot(chef[i],\n",
    "                 rug = True,\n",
    "                 color = 'blue')\n",
    "    plt.xlabel(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting outlier thresholds based on histograms\n",
    "\n",
    "total_meals_hi  = 180          # data starts to become skewed after this point\n",
    "           \n",
    "unique_meals_lo = 1.5          # no data points below this point\n",
    "unique_meals_hi = 9            # there's a sharp drop at 10\n",
    "\n",
    "contacts_cust_lo = 3           # there's a drop below 3\n",
    "contacts_cust_hi = 10          # uncharacteristic increase after 10 that does not follow normal distribution\n",
    "\n",
    "prod_viewed_lo = 1             # no data points below 1\n",
    "prod_viewed_hi = 10            # no data points above 10\n",
    "\n",
    "avg_site_time_hi = 175         # few customers spend over 175 seconds on the website\n",
    "\n",
    "canc_before_noon_hi = 5        # data skews after 5\n",
    " \n",
    "canc_after_noon_lo = 1         # very few data points below this number\n",
    "canc_after_noon_hi = 2         # very few data points after this number\n",
    "\n",
    "pc_logins_lo = 5               # very few data points below 5\n",
    "pc_logins_hi = 6               # very few data points above 6\n",
    "\n",
    "mobile_logins_lo = 1           # very few data points below 1\n",
    "mobile_logins_hi = 2           # very few data points above 2\n",
    "\n",
    "weekly_plan_hi = 14            # sharp drop after 14\n",
    "\n",
    "early_del_hi = 4               # sharp drop after 4\n",
    "\n",
    "late_del_hi = 7                # data skewed after this point\n",
    "\n",
    "avg_prep_time_lo = 80          # few points below 80\n",
    "avg_prep_time_hi = 230         # data skews after this point\n",
    "\n",
    "largest_order_lo = 2           # sharp drop below this point\n",
    "largest_order_hi = 7           # sharp drop after this point\n",
    "\n",
    "master_class_hi = 1            # more than 1 class is an outlier\n",
    "\n",
    "median_rating_lo = 2           # few points below 2\n",
    "median_rating_hi = 4           # very few points after 4\n",
    "\n",
    "avg_clicks_lo = 8              # few points below 8\n",
    "avg_clicks_hi = 17.5           # few points above 17.5\n",
    "\n",
    "#####\n",
    "\n",
    "revenue_lo = 500               # few values below 500\n",
    "revenue_hi = 2500              # small uncharacteristic rise after this point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "## Feature Engineering (outlier thresholds)                                 ##\n",
    "##############################################################################\n",
    "\n",
    "# Developing features (columns) for outliers based on previously-defined thresholds\n",
    "\n",
    "# Total Meals\n",
    "chef['out_total_meals'] = 0\n",
    "condition_hi = chef.loc[0:,'out_total_meals'][chef['TOTAL_MEALS_ORDERED'] > total_meals_hi]\n",
    "\n",
    "chef['out_total_meals'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "\n",
    "# Unique Meals Purchased\n",
    "chef['out_unique_meals'] = 0\n",
    "condition_hi = chef.loc[0:,'out_unique_meals'][chef['UNIQUE_MEALS_PURCH'] > unique_meals_hi]\n",
    "condition_lo = chef.loc[0:,'out_unique_meals'][chef['UNIQUE_MEALS_PURCH'] < unique_meals_lo]\n",
    "\n",
    "chef['out_unique_meals'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "chef['out_unique_meals'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# Contacts with Customer Service\n",
    "chef['out_contacts_cust'] = 0\n",
    "condition_hi = chef.loc[0:,'out_contacts_cust'][chef['CONTACTS_W_CUSTOMER_SERVICE'] > contacts_cust_hi]\n",
    "condition_lo = chef.loc[0:,'out_contacts_cust'][chef['CONTACTS_W_CUSTOMER_SERVICE'] < contacts_cust_lo]\n",
    "\n",
    "chef['out_contacts_cust'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "chef['out_contacts_cust'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# Product Categories Viewed\n",
    "chef['out_prod_viewed'] = 0\n",
    "condition_hi = chef.loc[0:,'out_prod_viewed'][chef['PRODUCT_CATEGORIES_VIEWED'] > prod_viewed_hi]\n",
    "condition_lo = chef.loc[0:,'out_prod_viewed'][chef['PRODUCT_CATEGORIES_VIEWED'] < prod_viewed_lo]\n",
    "\n",
    "chef['out_prod_viewed'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "chef['out_prod_viewed'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# Average Time per Site Visit\n",
    "chef['out_avg_site_time'] = 0\n",
    "condition_hi = chef.loc[0:,'out_avg_site_time'][chef['AVG_TIME_PER_SITE_VISIT'] > avg_site_time_hi]\n",
    "\n",
    "chef['out_avg_site_time'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "\n",
    "# Cancellations Before Noon\n",
    "chef['out_canc_before_noon'] = 0\n",
    "condition_hi = chef.loc[0:,'out_canc_before_noon'][chef['CANCELLATIONS_BEFORE_NOON'] > canc_before_noon_hi]\n",
    "\n",
    "chef['out_canc_before_noon'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "# Cancellations After Noon\n",
    "chef['out_canc_after_noon'] = 0\n",
    "condition_hi = chef.loc[0:,'out_canc_after_noon'][chef['CANCELLATIONS_AFTER_NOON'] > canc_after_noon_hi]\n",
    "condition_lo = chef.loc[0:,'out_canc_after_noon'][chef['CANCELLATIONS_AFTER_NOON'] < canc_after_noon_hi]\n",
    "\n",
    "chef['out_canc_after_noon'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "chef['out_canc_after_noon'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# PC Logins\n",
    "chef['out_pc_logins'] = 0\n",
    "condition_hi = chef.loc[0:,'out_pc_logins'][chef['PC_LOGINS'] > pc_logins_hi]\n",
    "condition_lo = chef.loc[0:,'out_pc_logins'][chef['PC_LOGINS'] < pc_logins_lo]\n",
    "\n",
    "chef['out_pc_logins'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "chef['out_pc_logins'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# Mobile Logins\n",
    "chef['out_mobile_logins'] = 0\n",
    "condition_hi = chef.loc[0:,'out_mobile_logins'][chef['MOBILE_LOGINS'] > mobile_logins_hi]\n",
    "condition_lo = chef.loc[0:,'out_mobile_logins'][chef['MOBILE_LOGINS'] < mobile_logins_lo]\n",
    "\n",
    "chef['out_mobile_logins'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "chef['out_mobile_logins'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# Weekly Plan\n",
    "chef['out_weekly_plan'] = 0\n",
    "condition_hi = chef.loc[0:,'out_weekly_plan'][chef['WEEKLY_PLAN'] > weekly_plan_hi]\n",
    "\n",
    "chef['out_weekly_plan'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "\n",
    "# Early Deliveries\n",
    "chef['out_early_deliveries'] = 0\n",
    "condition_hi = chef.loc[0:,'out_early_deliveries'][chef['EARLY_DELIVERIES'] > early_del_hi]\n",
    "\n",
    "chef['out_early_deliveries'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "# Late Deliveries\n",
    "chef['out_late_deliveries'] = 0\n",
    "condition_hi = chef.loc[0:,'out_late_deliveries'][chef['LATE_DELIVERIES'] > late_del_hi]\n",
    "\n",
    "chef['out_late_deliveries'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "\n",
    "# Average Preparation Video Time\n",
    "chef['out_avg_prep_vid_time'] = 0\n",
    "condition_hi = chef.loc[0:,'out_avg_prep_vid_time'][chef['AVG_PREP_VID_TIME'] > avg_prep_time_hi]\n",
    "condition_lo = chef.loc[0:,'out_avg_prep_vid_time'][chef['AVG_PREP_VID_TIME'] < avg_prep_time_lo]\n",
    "\n",
    "chef['out_avg_prep_vid_time'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "chef['out_avg_prep_vid_time'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# Largest Order\n",
    "chef['out_largest_order'] = 0\n",
    "condition_hi = chef.loc[0:,'out_largest_order'][chef['LARGEST_ORDER_SIZE'] > largest_order_hi]\n",
    "condition_lo = chef.loc[0:,'out_largest_order'][chef['LARGEST_ORDER_SIZE'] < largest_order_lo]\n",
    "\n",
    "chef['out_largest_order'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "chef['out_largest_order'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "\n",
    "# Master Classes Attended\n",
    "chef['out_master_classes'] = 0\n",
    "condition_hi = chef.loc[0:,'out_master_classes'][chef['MASTER_CLASSES_ATTENDED'] > master_class_hi]\n",
    "\n",
    "chef['out_master_classes'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "\n",
    "# Median Meal Rating\n",
    "chef['out_median_rating'] = 0\n",
    "condition_hi = chef.loc[0:,'out_median_rating'][chef['MEDIAN_MEAL_RATING'] > median_rating_hi]\n",
    "condition_lo = chef.loc[0:,'out_median_rating'][chef['MEDIAN_MEAL_RATING'] < median_rating_lo]\n",
    "\n",
    "chef['out_median_rating'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "chef['out_median_rating'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "# Average Clicks per Visit\n",
    "chef['out_avg_clicks'] = 0\n",
    "condition_hi = chef.loc[0:,'out_avg_clicks'][chef['AVG_CLICKS_PER_VISIT'] > avg_clicks_hi]\n",
    "condition_lo = chef.loc[0:,'out_avg_clicks'][chef['AVG_CLICKS_PER_VISIT'] < avg_clicks_lo]\n",
    "\n",
    "chef['out_avg_clicks'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "chef['out_avg_clicks'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "#####\n",
    "\n",
    "# Revenue\n",
    "chef['out_revenue'] = 0\n",
    "condition_hi = chef.loc[0:,'out_revenue'][chef['REVENUE'] > revenue_hi]\n",
    "condition_lo = chef.loc[0:,'out_revenue'][chef['REVENUE'] < revenue_lo]\n",
    "\n",
    "chef['out_revenue'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "chef['out_revenue'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Developing Trend-Based Features</h3><br>\n",
    "\n",
    "Similar to outlier analysis, trend analysis is performed to maximize model accuracy. This consists of identifying the point at which the trend of an explanatory variable vs. response variable (Revenue) scatterplot changes. These peaks and troughs will be of value because it could signify that an event occurred after this point that caused the trend change (i.e. caused a sudden drop or spike). <br>\n",
    "\n",
    "The trend-based analysis will comprise three steps: <br>\n",
    "1. Firstly a scatterplot will be created for every variable in the dataset.\n",
    "2. The point at which the scatterplot trend changes will be identified and flagged.\n",
    "3. From these trend thresholds, features (columns) for trend changes will be created to be included in the predictive model (if significant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########################\n",
    "# Visual EDA (Scatterplots)\n",
    "########################\n",
    "\n",
    "for i in all_variables:\n",
    "    fig, ax = plt.subplots(figsize = (10, 8))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.scatterplot(x = chef[i],\n",
    "                    y = chef['REVENUE'],\n",
    "                    color = 'blue')\n",
    "    plt.xlabel(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting thresholds at points where the trend changes\n",
    "\n",
    "total_meals_ordered_change = 150          # values start to scatter more after this point\n",
    "unique_meals_purch_change = 0             # zero inflated\n",
    "contacts_cust_change = 10                 # sudden, significant drop after this point\n",
    "product_categories_viewed_change = 5      # sudden increase at 6\n",
    "avg_time_site_visit_change = 200          # values scatter after this point\n",
    "canc_before_noon_change = 0               # zero inflated\n",
    "canc_after_noon_change = 0                # zero inflated\n",
    "pc_logins_change = 6                      # sudden drop after this point\n",
    "#mobile_logins_change = 1 \n",
    "weekly_plan_change = 0                    # zero inflated\n",
    "early_deliveries_change = 0               # zero inflated\n",
    "late_deliveries_change = 0                # zero inflated\n",
    "followed_recommendations_change = 0       # zero inflated\n",
    "avg_prep_vid_time_change = 280            # after steadily increasing, values start to scatter more here\n",
    "largest_order_size_change = 5             # after steadily increasing, values start a downward trend at this point\n",
    "master_classes_attended_change = 0        # zero inflated\n",
    "median_meal_rating_change = 4             # sudden drop here\n",
    "avg_clicks_per_visit_change = 10          # downward trend starts here after having had an upward trend\n",
    "total_photos_viewed_change = 0            # zero inflated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Developing trend-based features\n",
    "\n",
    "chef['change_Total_Meals_Ordered'] = 0\n",
    "condition = chef.loc[0:,'change_Total_Meals_Ordered'][chef['TOTAL_MEALS_ORDERED'] > total_meals_ordered_change]\n",
    "\n",
    "chef['change_Total_Meals_Ordered'].replace(to_replace = condition,\n",
    "                                   value      = 1,\n",
    "                                   inplace    = True)\n",
    "\n",
    "\n",
    "chef['change_Unique_Meals_Purch'] = 0\n",
    "condition = chef.loc[0:,'change_Unique_Meals_Purch'][chef['UNIQUE_MEALS_PURCH'] > unique_meals_purch_change]\n",
    "\n",
    "chef['change_Unique_Meals_Purch'].replace(to_replace = condition,\n",
    "                                   value      = 1,\n",
    "                                   inplace    = True)\n",
    "\n",
    "\n",
    "chef['change_Contacts_Customer_Service'] = 0\n",
    "condition = chef.loc[0:,'change_Contacts_Customer_Service'][chef['CONTACTS_W_CUSTOMER_SERVICE'] > contacts_cust_change]\n",
    "\n",
    "chef['change_Contacts_Customer_Service'].replace(to_replace = condition,\n",
    "                                   value      = 1,\n",
    "                                   inplace    = True)\n",
    "\n",
    "\n",
    "chef['change_Product_Categories_Viewed'] = 0\n",
    "condition = chef.loc[0:,'change_Product_Categories_Viewed'][chef['PRODUCT_CATEGORIES_VIEWED'] > product_categories_viewed_change]\n",
    "\n",
    "chef['change_Product_Categories_Viewed'].replace(to_replace = condition,\n",
    "                                   value      = 1,\n",
    "                                   inplace    = True)\n",
    "\n",
    "\n",
    "chef['change_Avg_Time_Site_Visit'] = 0\n",
    "condition = chef.loc[0:,'change_Avg_Time_Site_Visit'][chef['AVG_TIME_PER_SITE_VISIT'] > avg_time_site_visit_change]\n",
    "\n",
    "chef['change_Avg_Time_Site_Visit'].replace(to_replace = condition,\n",
    "                                   value      = 1,\n",
    "                                   inplace    = True)\n",
    "\n",
    "\n",
    "chef['change_Canc_Before_Noon'] = 0\n",
    "condition = chef.loc[0:,'change_Canc_Before_Noon'][chef['CANCELLATIONS_BEFORE_NOON'] > canc_before_noon_change]\n",
    "\n",
    "chef['change_Canc_Before_Noon'].replace(to_replace = condition,\n",
    "                                   value      = 1,\n",
    "                                   inplace    = True)\n",
    "\n",
    "\n",
    "chef['change_Canc_After_Noon'] = 0\n",
    "condition = chef.loc[0:,'change_Canc_After_Noon'][chef['CANCELLATIONS_AFTER_NOON'] > canc_after_noon_change]\n",
    "\n",
    "chef['change_Canc_After_Noon'].replace(to_replace = condition,\n",
    "                                   value      = 1,\n",
    "                                   inplace    = True)\n",
    "\n",
    "\n",
    "chef['change_PC_Logins'] = 0\n",
    "condition = chef.loc[0:,'change_PC_Logins'][chef['PC_LOGINS'] > pc_logins_change]\n",
    "\n",
    "chef['change_PC_Logins'].replace(to_replace = condition,\n",
    "                                   value      = 1,\n",
    "                                   inplace    = True)\n",
    "\n",
    "\n",
    "#chef['change_Mobile_Logins'] = 0\n",
    "#condition = chef.loc[0:,'change_Mobile_Logins'][chef['MOBILE_LOGINS'] > mobile_logins_change]\n",
    "\n",
    "#chef['change_Mobile_Logins'].replace(to_replace = condition,\n",
    "                                   #value      = 1,\n",
    "                                   #inplace    = True)\n",
    "\n",
    "\n",
    "chef['change_Weekly_Plan'] = 0\n",
    "condition = chef.loc[0:,'change_Weekly_Plan'][chef['WEEKLY_PLAN'] > weekly_plan_change]\n",
    "\n",
    "chef['change_Weekly_Plan'].replace(to_replace = condition,\n",
    "                                   value      = 1,\n",
    "                                   inplace    = True)\n",
    "\n",
    "\n",
    "chef['change_Early_Deliveries'] = 0\n",
    "condition = chef.loc[0:,'change_Early_Deliveries'][chef['EARLY_DELIVERIES'] > early_deliveries_change]\n",
    "\n",
    "chef['change_Early_Deliveries'].replace(to_replace = condition,\n",
    "                                   value      = 1,\n",
    "                                   inplace    = True)\n",
    "\n",
    "\n",
    "chef['change_Late_Deliveries'] = 0\n",
    "condition = chef.loc[0:,'change_Late_Deliveries'][chef['LATE_DELIVERIES'] > late_deliveries_change]\n",
    "\n",
    "chef['change_Late_Deliveries'].replace(to_replace = condition,\n",
    "                                   value      = 1,\n",
    "                                   inplace    = True)\n",
    "\n",
    "\n",
    "chef['change_Followed_Recommendations'] = 0\n",
    "condition = chef.loc[0:,'change_Followed_Recommendations'][chef['FOLLOWED_RECOMMENDATIONS_PCT'] > followed_recommendations_change]\n",
    "\n",
    "chef['change_Followed_Recommendations'].replace(to_replace = condition,\n",
    "                                   value      = 1,\n",
    "                                   inplace    = True)\n",
    "\n",
    "\n",
    "chef['change_Avg_Prep_Vid_Time'] = 0\n",
    "condition = chef.loc[0:,'change_Avg_Prep_Vid_Time'][chef['AVG_PREP_VID_TIME'] > avg_prep_vid_time_change]\n",
    "\n",
    "chef['change_Avg_Prep_Vid_Time'].replace(to_replace = condition,\n",
    "                                   value      = 1,\n",
    "                                   inplace    = True)\n",
    "\n",
    "\n",
    "chef['change_Largest_Order_Size'] = 0\n",
    "condition = chef.loc[0:,'change_Largest_Order_Size'][chef['LARGEST_ORDER_SIZE'] > largest_order_size_change]\n",
    "\n",
    "chef['change_Largest_Order_Size'].replace(to_replace = condition,\n",
    "                                   value      = 1,\n",
    "                                   inplace    = True)\n",
    "\n",
    "\n",
    "chef['change_Master_Classes_Attended'] = 0\n",
    "condition = chef.loc[0:,'change_Master_Classes_Attended'][chef['MASTER_CLASSES_ATTENDED'] > master_classes_attended_change]\n",
    "\n",
    "chef['change_Master_Classes_Attended'].replace(to_replace = condition,\n",
    "                                   value      = 1,\n",
    "                                   inplace    = True)\n",
    "\n",
    "\n",
    "chef['change_Median_Meal_Rating'] = 0\n",
    "condition = chef.loc[0:,'change_Median_Meal_Rating'][chef['MEDIAN_MEAL_RATING'] > median_meal_rating_change]\n",
    "\n",
    "chef['change_Median_Meal_Rating'].replace(to_replace = condition,\n",
    "                                   value      = 1,\n",
    "                                   inplace    = True)\n",
    "\n",
    "\n",
    "chef['change_Avg_Clicks_Per_Visit'] = 0\n",
    "condition = chef.loc[0:,'change_Avg_Clicks_Per_Visit'][chef['AVG_CLICKS_PER_VISIT'] > avg_clicks_per_visit_change]\n",
    "\n",
    "chef['change_Avg_Clicks_Per_Visit'].replace(to_replace = condition,\n",
    "                                   value      = 1,\n",
    "                                   inplace    = True)\n",
    "\n",
    "\n",
    "chef['change_Total_Photos_Viewed'] = 0\n",
    "condition = chef.loc[0:,'change_Total_Photos_Viewed'][chef['TOTAL_PHOTOS_VIEWED'] > total_photos_viewed_change]\n",
    "\n",
    "chef['change_Total_Photos_Viewed'].replace(to_replace = condition,\n",
    "                                   value      = 1,\n",
    "                                   inplace    = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Encoding Categorical Variables</h3><br>\n",
    "\n",
    "\"EMAIL\" was identified to be the only categorical variable. To include this categorical variable in the model as a feature and further improve the model's accuracy, it needs to be one-hot encoded to be converted from a string into an integer. <br>\n",
    "\n",
    "To do this, the domains will be separated from each email, and grouped according to whether the domain is junk, personal, or professional email (per specifications given by the marketing team). <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting emails\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []     \n",
    "\n",
    "# looping over each email address\n",
    "for index, col in chef.iterrows():\n",
    "    \n",
    "    # splitting email domain at '@'\n",
    "    split_email = chef.loc[index, 'EMAIL'].split(sep = '@')\n",
    "    \n",
    "    # appending placeholder_lst with the results\n",
    "    placeholder_lst.append(split_email)\n",
    "    \n",
    "\n",
    "# converting placeholder_lst into a DataFrame \n",
    "email_df = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "\n",
    "# displaying the results\n",
    "email_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating with original DataFrame \n",
    "\n",
    "# Renaming column to concatenate\n",
    "email_df.columns = ['name' , 'email_domain']     # Renaming columns 0 and 1 from before to \"name\" and \"domain\"\n",
    "\n",
    "\n",
    "# Concatenating email_domain with chef DataFrame\n",
    "chef = pd.concat([chef, email_df['email_domain']],\n",
    "                   axis = 1)\n",
    "\n",
    "\n",
    "# Printing value counts of email_domain\n",
    "chef.loc[: ,'email_domain'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating domains into higher-level categories\n",
    "\n",
    "# Email domain types\n",
    "professional_email_domains = ['@mmm.com',\n",
    "                              '@amex.com',\n",
    "                              '@apple.com',\n",
    "                              '@boeing.com',\n",
    "                              '@caterpillar.com',\n",
    "                              '@chevron.com',\n",
    "                              '@cisco.com',\n",
    "                              '@cocacola.com',\n",
    "                              '@disney.com',\n",
    "                              '@dupont.com',\n",
    "                              '@exxon.com',\n",
    "                              '@ge.org',\n",
    "                              '@goldmansacs.com',\n",
    "                              '@homedepot.com',\n",
    "                              '@ibm.com',\n",
    "                              '@intel.com',\n",
    "                              '@jnj.com',\n",
    "                              '@jpmorgan.com',\n",
    "                              '@mcdonalds.com',\n",
    "                              '@merck.com',\n",
    "                              '@microsoft.com',\n",
    "                              '@nike.com',\n",
    "                              '@pfizer.com',\n",
    "                              '@pg.com',\n",
    "                              '@travelers.com',\n",
    "                              '@unitedtech.com',\n",
    "                              '@unitedhealth.com',\n",
    "                              '@verizon.com',\n",
    "                              '@visa.com',\n",
    "                              '@walmart.com']\n",
    " \n",
    "            \n",
    "personal_email_domains = ['@gmail.com', \n",
    "                          '@yahoo.com',\n",
    "                          '@protonmail.com']\n",
    "\n",
    "\n",
    "junk_email_domains  = ['@me.com',\n",
    "                       '@aol.com',\n",
    "                       '@hotmail.com',\n",
    "                       '@live.com',\n",
    "                       '@msn.com',\n",
    "                       '@passport.com']\n",
    "\n",
    "\n",
    "# Placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "\n",
    "# Looping to group observations by domain type\n",
    "for domain in chef['email_domain']:\n",
    "        if '@' + domain in professional_email_domains:\n",
    "            placeholder_lst.append('professional')\n",
    "    \n",
    "        elif '@' + domain in personal_email_domains:\n",
    "            placeholder_lst.append('personal')\n",
    "            \n",
    "        elif '@' + domain in junk_email_domains:\n",
    "            placeholder_lst.append('junk')\n",
    "            \n",
    "        else:\n",
    "            print('Unknown')\n",
    "\n",
    "\n",
    "# Concatenating with original DataFrame\n",
    "chef['domain_group'] = pd.Series(placeholder_lst)\n",
    "\n",
    "\n",
    "# Checking results\n",
    "chef['domain_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding emails\n",
    "one_hot_domain_group = pd.get_dummies(chef['domain_group'])\n",
    "\n",
    "# Joining encoded variables with dataset\n",
    "chef = chef.join([one_hot_domain_group])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a boxplot on the categorical variable to see if type of domain \n",
    "# (junk, personal, professional) makes a difference\n",
    "\n",
    "chef.boxplot(column = 'REVENUE',\n",
    "                 by = 'domain_group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Boxplot Output:</strong><br>\n",
    "\n",
    "The median lines are similar for all email domain types (junk, personal, or professional domain), so it would appear as though the type of email domain does not have a significant impact on revenue. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping categorical variables after they've been encoded\n",
    "chef_dropped = chef.drop(['EMAIL', 'email_domain', 'domain_group'],\n",
    "               axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Running Regression Models</h3><br>\n",
    "\n",
    "With the features engineered into the original chef dataset, the models are now ready to be run.<br>\n",
    "\n",
    "After building the train-test split, four different models will be run and tested to compare the scores of each one and see which one results in the highest training and testing accuracy. To avoid overfitting and optimize stability of the model, the goal is to have both scores within 0.05 of one another.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Re-running Pearson correlation matrix with new features included \n",
    "# (again, to get an overview of initial correlation)\n",
    "\n",
    "df_corr = chef.corr().round(2)\n",
    "\n",
    "# Printing (Pearson) correlations with Revenue\n",
    "print(df_corr.loc['REVENUE'].sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "##### Decided not to scale the data, as it caused scores to decrease in accuracy #####\n",
    "\n",
    "### Scaling the data ###\n",
    "\n",
    "#from sklearn.neighbors import KNeighborsRegressor # KNN for Regression\n",
    "#from sklearn.preprocessing import StandardScaler # standard scaler\n",
    "\n",
    "\n",
    "#chef_drop_string = chef.drop(['NAME',\n",
    "                             # 'FIRST_NAME',\n",
    "                             # 'FAMILY_NAME',\n",
    "                             # 'EMAIL',\n",
    "                             # 'email_domain',\n",
    "                             # 'domain_group'], \n",
    "                             #  axis = 1)\n",
    "\n",
    "\n",
    "# INSTANTIATING a StandardScaler() object\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING the scaler with housing_data\n",
    "#scaler.fit(chef_drop_string)   \n",
    "\n",
    "# ^ Only want to standardize the X side, because we only have one y variable so the variance would be all the same\n",
    "# housing_data is all our data except SalePrice and OutSalePrice\n",
    "\n",
    "\n",
    "# TRANSFORMING our data after fit\n",
    "#X_scaled = scaler.transform(chef_drop_string)\n",
    "\n",
    "\n",
    "# converting scaled data into a DataFrame\n",
    "#X_scaled_df = pd.DataFrame(X_scaled)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "#X_scaled_df.columns = chef_drop_string.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Ordinary Least Squares (OLS) Regression</h4><br>\n",
    "\n",
    "First, an initial OLS regression will be fun on every variable and feature to analyze p-values and remove insignificant variables one-by-one. <br>\n",
    "\n",
    "A logarithm transformation will be done on Revenue to improve linear regression analysis (improve the linear condition for the data), and to allow for easier interpretation in terms of percentage scale.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Log transformation on Revenue\n",
    "\n",
    "import numpy as np\n",
    "chef['log_revenue'] = np.log(chef['REVENUE'])\n",
    "\n",
    "### OLS MODEL ###\n",
    "\n",
    "# Instantiating a model object\n",
    "lm_initial = smf.ols(formula = \"\"\"chef['log_revenue'] ~ chef['CROSS_SELL_SUCCESS'] +\n",
    "                                               chef['TOTAL_MEALS_ORDERED'] + \n",
    "                                               chef['UNIQUE_MEALS_PURCH'] +\n",
    "                                               chef['CONTACTS_W_CUSTOMER_SERVICE'] + \n",
    "                                               chef['PRODUCT_CATEGORIES_VIEWED'] +\n",
    "                                               chef['AVG_TIME_PER_SITE_VISIT'] + \n",
    "                                               chef['MOBILE_NUMBER'] + \n",
    "                                               chef['CANCELLATIONS_BEFORE_NOON'] +\n",
    "                                               chef['CANCELLATIONS_AFTER_NOON'] + \n",
    "                                               chef['TASTES_AND_PREFERENCES'] + \n",
    "                                               chef['MOBILE_LOGINS'] +\n",
    "                                               chef['PC_LOGINS'] +\n",
    "                                               chef['WEEKLY_PLAN'] + \n",
    "                                               chef['EARLY_DELIVERIES'] + \n",
    "                                               chef['LATE_DELIVERIES'] +\n",
    "                                               chef['PACKAGE_LOCKER'] + \n",
    "                                               chef['REFRIGERATED_LOCKER'] + \n",
    "                                               chef['FOLLOWED_RECOMMENDATIONS_PCT'] +\n",
    "                                               chef['AVG_PREP_VID_TIME'] + \n",
    "                                               chef['LARGEST_ORDER_SIZE'] + \n",
    "                                               chef['MASTER_CLASSES_ATTENDED'] +\n",
    "                                               chef['MEDIAN_MEAL_RATING'] + \n",
    "                                               chef['AVG_CLICKS_PER_VISIT'] + \n",
    "                                               chef['TOTAL_PHOTOS_VIEWED'] +\n",
    "                                               chef['out_total_meals'] +\n",
    "                                               chef['out_unique_meals'] +\n",
    "                                               chef['out_contacts_cust'] +\n",
    "                                               chef['out_prod_viewed'] +\n",
    "                                               chef['out_avg_site_time'] +\n",
    "                                               chef['out_canc_before_noon'] +\n",
    "                                               chef['out_pc_logins'] +\n",
    "                                               chef['out_mobile_logins'] +\n",
    "                                               chef['out_weekly_plan'] +\n",
    "                                               chef['out_early_deliveries'] +\n",
    "                                               chef['out_late_deliveries'] +\n",
    "                                               chef['out_avg_prep_vid_time'] +\n",
    "                                               chef['out_largest_order'] +\n",
    "                                               chef['out_master_classes'] +\n",
    "                                               chef['out_median_rating'] +\n",
    "                                               chef['out_avg_clicks'] +\n",
    "                                               chef['change_Total_Meals_Ordered'] +\n",
    "                                               chef['change_Unique_Meals_Purch'] +\n",
    "                                               chef['change_Contacts_Customer_Service'] +\n",
    "                                               chef['change_Product_Categories_Viewed'] +\n",
    "                                               chef['change_Avg_Time_Site_Visit'] +\n",
    "                                               chef['change_Canc_Before_Noon'] +\n",
    "                                               chef['change_Canc_After_Noon'] +\n",
    "                                               chef['change_PC_Logins'] +\n",
    "                                               chef['change_Weekly_Plan'] +\n",
    "                                               chef['change_Early_Deliveries'] +\n",
    "                                               chef['change_Late_Deliveries'] +\n",
    "                                               chef['change_Followed_Recommendations'] +\n",
    "                                               chef['change_Avg_Prep_Vid_Time'] +\n",
    "                                               chef['change_Largest_Order_Size'] +\n",
    "                                               chef['change_Master_Classes_Attended'] +\n",
    "                                               chef['change_Median_Meal_Rating'] +\n",
    "                                               chef['change_Avg_Clicks_Per_Visit'] +\n",
    "                                               chef['change_Total_Photos_Viewed'] +\n",
    "                                               chef['professional'] +\n",
    "                                               chef['personal'] +\n",
    "                                               chef['junk']\"\"\",\n",
    "                                               data = chef)\n",
    "\n",
    "# Fitting the model based on the data\n",
    "results_initial = lm_initial.fit()\n",
    "\n",
    "\n",
    "# Printing the results\n",
    "print(results_initial.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Improved OLS Regression</h4><br>\n",
    "\n",
    "After analyzing the initial OLS Regression results in which all variables were measured against the response variable, Revenue, features were removed one-by-one if its p-value was greater than 0.05, from highest p-value. Another OLS Linear Regression model was created and run without eliminated variables and features to see if the R-squared value were better each time, and if all p-values were 0.05 or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### OLS MODEL 2 ###\n",
    "\n",
    "# Instantiating a model object\n",
    "lm_best = smf.ols(formula = \"\"\"chef['log_revenue'] ~ chef['TOTAL_MEALS_ORDERED'] + \n",
    "                                               chef['UNIQUE_MEALS_PURCH'] +\n",
    "                                               chef['CONTACTS_W_CUSTOMER_SERVICE'] + \n",
    "                                               chef['AVG_TIME_PER_SITE_VISIT'] + \n",
    "                                               chef['REFRIGERATED_LOCKER'] + \n",
    "                                               chef['AVG_PREP_VID_TIME'] + \n",
    "                                               chef['LARGEST_ORDER_SIZE'] + \n",
    "                                               chef['MASTER_CLASSES_ATTENDED'] +\n",
    "                                               chef['MEDIAN_MEAL_RATING'] + \n",
    "                                               chef['out_unique_meals'] +\n",
    "                                               chef['out_largest_order'] +\n",
    "                                               chef['out_master_classes'] +\n",
    "                                               chef['out_median_rating'] +\n",
    "                                               chef['change_Unique_Meals_Purch'] +\n",
    "                                               chef['change_Contacts_Customer_Service'] +\n",
    "                                               chef['change_Canc_After_Noon'] +\n",
    "                                               chef['change_Weekly_Plan'] +\n",
    "                                               chef['change_Avg_Prep_Vid_Time'] +\n",
    "                                               chef['change_Master_Classes_Attended'] +\n",
    "                                               chef['change_Median_Meal_Rating'] +\n",
    "                                               chef['change_Avg_Clicks_Per_Visit'] +\n",
    "                                               chef['change_Total_Photos_Viewed'] +\n",
    "                                               chef['professional'] +\n",
    "                                               chef['personal'] +\n",
    "                                               chef['junk']\"\"\",\n",
    "                                               data = chef)\n",
    "\n",
    "\n",
    "# Fitting the model based on the data\n",
    "results_lm = lm_best.fit()\n",
    "\n",
    "\n",
    "# Printing the results\n",
    "print(results_lm.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "##### Removed variables #####\n",
    "\n",
    "#                                               chef['TOTAL_PHOTOS_VIEWED'] +\n",
    "#                                               chef['MOBILE_LOGINS'] +\n",
    "#                                               chef['out_pc_logins'] +\n",
    "#                                               chef['change_PC_Logins'] +\n",
    "#                                               chef['change_Avg_Time_Site_Visit'] +\n",
    "#                                               chef['change_Late_Deliveries'] +\n",
    "#                                               chef['out_canc_before_noon'] +\n",
    "#                                               chef['CANCELLATIONS_BEFORE_NOON'] +\n",
    "#                                               chef['PRODUCT_CATEGORIES_VIEWED'] +\n",
    "#                                               chef['CANCELLATIONS_AFTER_NOON'] + \n",
    "#                                               chef['out_avg_clicks'] +\n",
    "#                                               chef['change_Canc_Before_Noon'] +\n",
    "#                                               chef['PACKAGE_LOCKER'] + \n",
    "#                                               chef['PC_LOGINS'] +\n",
    "#                                               chef['change_Total_Meals_Ordered'] +\n",
    "#                                               chef['out_prod_viewed'] +\n",
    "#                                               chef['out_early_deliveries'] +\n",
    "#                                               chef['change_Early_Deliveries'] +\n",
    "#                                               chef['change_Largest_Order_Size'] +\n",
    "#                                               chef['TASTES_AND_PREFERENCES'] +\n",
    "#                                               chef['WEEKLY_PLAN'] + \n",
    "#                                               chef['MOBILE_NUMBER'] + \n",
    "#                                               chef['LATE_DELIVERIES'] +\n",
    "#                                               chef['out_mobile_logins'] +\n",
    "#                                               chef['out_late_deliveries'] +\n",
    "#                                               chef['out_avg_prep_vid_time'] +\n",
    "#                                               chef['EARLY_DELIVERIES'] + \n",
    "#                                               chef['out_avg_site_time'] +\n",
    "#                                               chef['AVG_CLICKS_PER_VISIT'] + \n",
    "#                                               chef['change_Followed_Recommendations'] +\n",
    "#                                               chef['FOLLOWED_RECOMMENDATIONS_PCT'] +\n",
    "#                                               chef['out_weekly_plan'] +\n",
    "#                                               chef['change_Product_Categories_Viewed'] +\n",
    "#                                               chef['out_contacts_cust'] +\n",
    "#chef['CROSS_SELL_SUCCESS'] +\n",
    "#                                               chef['out_total_meals'] +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing explanatory variable data\n",
    "chef_explanatory   = chef.drop(['REVENUE',                    # Response variable\n",
    "                               'log_revenue',                 # Transformed response variable\n",
    "                               'out_revenue',                 # Revenue outliers - this was engineered\n",
    "                               'NAME',                        # Dropping string objects in the dataset\n",
    "                               'EMAIL',\n",
    "                               'email_domain', \n",
    "                               'domain_group',\n",
    "                               'FIRST_NAME',\n",
    "                               'FAMILY_NAME',\n",
    "                               'TOTAL_PHOTOS_VIEWED',         #  Dropping insignificant variables in the dataset according to p-value \n",
    "                               'MOBILE_LOGINS',\n",
    "                               'out_pc_logins',\n",
    "                               'change_PC_Logins',\n",
    "                               'change_Avg_Time_Site_Visit',\n",
    "                               'change_Late_Deliveries',\n",
    "                               'out_canc_before_noon',\n",
    "                               'CANCELLATIONS_BEFORE_NOON',\n",
    "                               'PRODUCT_CATEGORIES_VIEWED',\n",
    "                               'out_avg_clicks',\n",
    "                               'change_Canc_Before_Noon',\n",
    "                               'PACKAGE_LOCKER',\n",
    "                               'PC_LOGINS',\n",
    "                               'change_Total_Meals_Ordered',\n",
    "                               'out_prod_viewed',\n",
    "                               'out_early_deliveries',\n",
    "                               'change_Early_Deliveries',\n",
    "                               'change_Largest_Order_Size',\n",
    "                               'TASTES_AND_PREFERENCES',\n",
    "                               'WEEKLY_PLAN',\n",
    "                               'MOBILE_NUMBER',\n",
    "                               'LATE_DELIVERIES',\n",
    "                               'out_mobile_logins',\n",
    "                               'out_late_deliveries',\n",
    "                               'out_avg_prep_vid_time',\n",
    "                               'EARLY_DELIVERIES',\n",
    "                               'out_avg_site_time',\n",
    "                               'AVG_CLICKS_PER_VISIT',\n",
    "                               'change_Followed_Recommendations',\n",
    "                               'FOLLOWED_RECOMMENDATIONS_PCT',\n",
    "                               'out_weekly_plan',\n",
    "                               'change_Product_Categories_Viewed',\n",
    "                               'out_contacts_cust',\n",
    "                               'CROSS_SELL_SUCCESS',\n",
    "                               'out_total_meals'],  \n",
    "                                axis = 1) \n",
    "\n",
    "# Preparing response variable data\n",
    "chef_target = chef.loc[:, 'log_revenue']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Building a Train-Test Split</h4><br>\n",
    "\n",
    "A train-test split will be defined, where 75% of the data will be used to train the model, and the other 25% of the data will be used to test it. This split is done so that the model does not overfit - i.e. adhere too closely to existing data - and ensure that it predicts accurately on new observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            chef_explanatory,\n",
    "            chef_target,\n",
    "            test_size = 0.25,\n",
    "            random_state = 222)\n",
    "\n",
    "\n",
    "# Training set \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# Testing set\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>OLS Regression Model in scikit-learn</h4><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Applying OLS Regression Model in scikit-learn ###\n",
    "\n",
    "lr = sklearn.linear_model.LinearRegression()\n",
    "\n",
    "# Fitting to the training data\n",
    "lr_fit = lr.fit(X_train, y_train) \n",
    "\n",
    "\n",
    "# Predicting on new data \n",
    "lr_pred = lr_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# Scoring the results\n",
    "print('Training Score:', lr.score(X_train, y_train).round(4))  # Going to tell us based on our model how much deviance is there\n",
    "print('Testing Score:',  lr.score(X_test, y_test).round(4))    # Seeing if it's too attached to our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Ridge Regression Model</h4><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a model object\n",
    "ridge_model = sklearn.linear_model.Ridge()\n",
    "\n",
    "# FITTING the training data\n",
    "ridge_fit  = ridge_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "ridge_pred = ridge_fit.predict(X_test)\n",
    "\n",
    "print('Training Score:', ridge_model.score(X_train, y_train).round(4))\n",
    "print('Testing Score:',  ridge_model.score(X_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use -- saving as an object for efficiency\n",
    "ridge_train_score = ridge_model.score(X_train, y_train).round(4)\n",
    "ridge_test_score  = ridge_model.score(X_test, y_test).round(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Lasso Regression Model</h4><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a model object\n",
    "lasso_model = sklearn.linear_model.Lasso()\n",
    "\n",
    "# FITTING the training data\n",
    "lasso_fit = lasso_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "lasso_pred = lasso_fit.predict(X_test)\n",
    "\n",
    "print('Training Score:', lasso_model.score(X_train, y_train).round(4))\n",
    "print('Testing Score:',  lasso_model.score(X_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "lasso_train_score = lasso_model.score(X_train, y_train).round(4)\n",
    "lasso_test_score  = lasso_model.score(X_test, y_test).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Gradient Boost Regression Model</h4><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# INSTANTIATING a model object\n",
    "gradient_model = sklearn.ensemble.GradientBoostingRegressor(n_estimators = 100,\n",
    "                                                            min_samples_leaf = 123,\n",
    "                                                            max_depth = 3,\n",
    "                                                            random_state = 222)\n",
    "\n",
    "# FITTING the training data\n",
    "gradient_fit = gradient_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "gradient_pred = gradient_fit.predict(X_test)\n",
    "\n",
    "print('Training Score:', gradient_model.score(X_train, y_train).round(4))\n",
    "print('Testing Score:',  gradient_model.score(X_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "gradient_train_score = gradient_model.score(X_train, y_train).round(4)\n",
    "gradient_test_score  = gradient_model.score(X_test, y_test).round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
